{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Short cut\n",
    "Shift + Enter: Run the current cell and move to the next cell.\n",
    "Ctrl + Enter: Run the current cell and stay on the same cell.\n",
    "Alt + Enter: Run the current cell and insert a new cell below.\n",
    "Esc: Enter command mode (you can navigate between cells using arrow keys).\n",
    "Enter: Enter edit mode (to edit the content of a cell).\n",
    "A: Insert a new cell above the current cell.\n",
    "B: Insert a new cell below the current cell.\n",
    "X: Cut the current cell.\n",
    "C: Copy the current cell.\n",
    "V: Paste cells below the current cell.\n",
    "D, D (press D twice): Delete the current cell.\n",
    "Z: Undo cell deletion.\n",
    "M: Change the current cell type to Markdown.\n",
    "Y: Change the current cell type to Code.\n",
    "1 to 6: Change the current cell to heading levels 1 to 6.\n",
    "Shift + Up/Down Arrow: Select multiple cells at once.\n",
    "Shift + M: Merge selected cells.\n",
    "Ctrl + S: Save the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year-Month</th>\n",
       "      <th>Agency Number</th>\n",
       "      <th>Agency Name</th>\n",
       "      <th>Cardholder Last Name</th>\n",
       "      <th>Cardholder First Initial</th>\n",
       "      <th>Description</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Vendor</th>\n",
       "      <th>Transaction Date</th>\n",
       "      <th>Posted Date</th>\n",
       "      <th>Merchant Category Code (MCC)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201307</td>\n",
       "      <td>1000</td>\n",
       "      <td>OKLAHOMA STATE UNIVERSITY</td>\n",
       "      <td>Mason</td>\n",
       "      <td>C</td>\n",
       "      <td>GENERAL PURCHASE</td>\n",
       "      <td>890.00</td>\n",
       "      <td>NACAS</td>\n",
       "      <td>07/30/2013 12:00:00 AM</td>\n",
       "      <td>07/31/2013 12:00:00 AM</td>\n",
       "      <td>CHARITABLE AND SOCIAL SERVICE ORGANIZATIONS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201307</td>\n",
       "      <td>1000</td>\n",
       "      <td>OKLAHOMA STATE UNIVERSITY</td>\n",
       "      <td>Mason</td>\n",
       "      <td>C</td>\n",
       "      <td>ROOM CHARGES</td>\n",
       "      <td>368.96</td>\n",
       "      <td>SHERATON HOTEL</td>\n",
       "      <td>07/30/2013 12:00:00 AM</td>\n",
       "      <td>07/31/2013 12:00:00 AM</td>\n",
       "      <td>SHERATON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201307</td>\n",
       "      <td>1000</td>\n",
       "      <td>OKLAHOMA STATE UNIVERSITY</td>\n",
       "      <td>Massey</td>\n",
       "      <td>J</td>\n",
       "      <td>GENERAL PURCHASE</td>\n",
       "      <td>165.82</td>\n",
       "      <td>SEARS.COM 9300</td>\n",
       "      <td>07/29/2013 12:00:00 AM</td>\n",
       "      <td>07/31/2013 12:00:00 AM</td>\n",
       "      <td>DIRCT MARKETING/DIRCT MARKETERS--NOT ELSEWHERE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201307</td>\n",
       "      <td>1000</td>\n",
       "      <td>OKLAHOMA STATE UNIVERSITY</td>\n",
       "      <td>Massey</td>\n",
       "      <td>T</td>\n",
       "      <td>GENERAL PURCHASE</td>\n",
       "      <td>96.39</td>\n",
       "      <td>WAL-MART #0137</td>\n",
       "      <td>07/30/2013 12:00:00 AM</td>\n",
       "      <td>07/31/2013 12:00:00 AM</td>\n",
       "      <td>GROCERY STORES,AND SUPERMARKETS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201307</td>\n",
       "      <td>1000</td>\n",
       "      <td>OKLAHOMA STATE UNIVERSITY</td>\n",
       "      <td>Mauro-Herrera</td>\n",
       "      <td>M</td>\n",
       "      <td>HAMMERMILL COPY PLUS COPY EA</td>\n",
       "      <td>125.96</td>\n",
       "      <td>STAPLES DIRECT</td>\n",
       "      <td>07/30/2013 12:00:00 AM</td>\n",
       "      <td>07/31/2013 12:00:00 AM</td>\n",
       "      <td>STATIONERY, OFFICE SUPPLIES, PRINTING AND WRIT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year-Month  Agency Number                Agency Name Cardholder Last Name  \\\n",
       "0      201307           1000  OKLAHOMA STATE UNIVERSITY                Mason   \n",
       "1      201307           1000  OKLAHOMA STATE UNIVERSITY                Mason   \n",
       "2      201307           1000  OKLAHOMA STATE UNIVERSITY               Massey   \n",
       "3      201307           1000  OKLAHOMA STATE UNIVERSITY               Massey   \n",
       "4      201307           1000  OKLAHOMA STATE UNIVERSITY        Mauro-Herrera   \n",
       "\n",
       "  Cardholder First Initial                   Description  Amount  \\\n",
       "0                        C              GENERAL PURCHASE  890.00   \n",
       "1                        C                  ROOM CHARGES  368.96   \n",
       "2                        J              GENERAL PURCHASE  165.82   \n",
       "3                        T              GENERAL PURCHASE   96.39   \n",
       "4                        M  HAMMERMILL COPY PLUS COPY EA  125.96   \n",
       "\n",
       "           Vendor        Transaction Date             Posted Date  \\\n",
       "0           NACAS  07/30/2013 12:00:00 AM  07/31/2013 12:00:00 AM   \n",
       "1  SHERATON HOTEL  07/30/2013 12:00:00 AM  07/31/2013 12:00:00 AM   \n",
       "2  SEARS.COM 9300  07/29/2013 12:00:00 AM  07/31/2013 12:00:00 AM   \n",
       "3  WAL-MART #0137  07/30/2013 12:00:00 AM  07/31/2013 12:00:00 AM   \n",
       "4  STAPLES DIRECT  07/30/2013 12:00:00 AM  07/31/2013 12:00:00 AM   \n",
       "\n",
       "                        Merchant Category Code (MCC)  \n",
       "0        CHARITABLE AND SOCIAL SERVICE ORGANIZATIONS  \n",
       "1                                           SHERATON  \n",
       "2  DIRCT MARKETING/DIRCT MARKETERS--NOT ELSEWHERE...  \n",
       "3                    GROCERY STORES,AND SUPERMARKETS  \n",
       "4  STATIONERY, OFFICE SUPPLIES, PRINTING AND WRIT...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C:/Users/STEVEN H/Desktop/5420 anomaly detection/2.  Feature Engineering Credit card Transaction Data/5420 a2/\" \n",
    "df = pd.read_csv(path + 'purchase_credit_card.csv') #, encoding = \"ISO-8859-1\")    \n",
    "df.head(5)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442458, 11)\n",
      "Index(['Year-Month', 'Agency Number', 'Agency Name', 'Cardholder Last Name',\n",
      "       'Cardholder First Initial', 'Description', 'Amount', 'Vendor',\n",
      "       'Transaction Date', 'Posted Date', 'Merchant Category Code (MCC)'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year-Month</th>\n",
       "      <th>Agency Number</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>442458.000000</td>\n",
       "      <td>442458.000000</td>\n",
       "      <td>4.424580e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>201357.284375</td>\n",
       "      <td>42785.860353</td>\n",
       "      <td>4.249912e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47.107417</td>\n",
       "      <td>33378.461293</td>\n",
       "      <td>5.266509e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>201307.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>-4.286304e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>201309.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>3.091000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>201401.000000</td>\n",
       "      <td>47700.000000</td>\n",
       "      <td>1.048900e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>201404.000000</td>\n",
       "      <td>76000.000000</td>\n",
       "      <td>3.450000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>201406.000000</td>\n",
       "      <td>98000.000000</td>\n",
       "      <td>1.903858e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Year-Month  Agency Number        Amount\n",
       "count  442458.000000  442458.000000  4.424580e+05\n",
       "mean   201357.284375   42785.860353  4.249912e+02\n",
       "std        47.107417   33378.461293  5.266509e+03\n",
       "min    201307.000000    1000.000000 -4.286304e+04\n",
       "25%    201309.000000    1000.000000  3.091000e+01\n",
       "50%    201401.000000   47700.000000  1.048900e+02\n",
       "75%    201404.000000   76000.000000  3.450000e+02\n",
       "max    201406.000000   98000.000000  1.903858e+06"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check dimensions of the dataset, we found it has 442,458 rows and 11 columns \n",
    "print(df.shape)\n",
    "print(df.columns) # check column names\n",
    "df.describe() # Get the Simple Summary Statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 442458 entries, 0 to 442457\n",
      "Data columns (total 11 columns):\n",
      " #   Column                        Non-Null Count   Dtype  \n",
      "---  ------                        --------------   -----  \n",
      " 0   Year-Month                    442458 non-null  int64  \n",
      " 1   Agency Number                 442458 non-null  int64  \n",
      " 2   Agency Name                   442458 non-null  object \n",
      " 3   Cardholder Last Name          442458 non-null  object \n",
      " 4   Cardholder First Initial      442458 non-null  object \n",
      " 5   Description                   442458 non-null  object \n",
      " 6   Amount                        442458 non-null  float64\n",
      " 7   Vendor                        442458 non-null  object \n",
      " 8   Transaction Date              442458 non-null  object \n",
      " 9   Posted Date                   442458 non-null  object \n",
      " 10  Merchant Category Code (MCC)  442458 non-null  object \n",
      "dtypes: float64(1), int64(2), object(8)\n",
      "memory usage: 37.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Post date-transaction date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Transaction Date'] = pd.to_datetime(df['Transaction Date'])\n",
    "df['Posted Date'] = pd.to_datetime(df['Posted Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Date_Diff, represents the time difference in days between the transaction date and the posted date. It can provide insights into how quickly transactions are processed or if there are any delays in posting. Thus, this feature do have benefits for the business"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Average amounts spent per transaction in the past one week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='Transaction Date')\n",
    "\n",
    "def rolling_amount(df, window, agg_func):\n",
    "    return df.rolling(window, on='Transaction Date')['Amount'].agg(agg_func)\n",
    "\n",
    "df['Avg_Amount_7_days'] = df.groupby('Cardholder Last Name').apply(rolling_amount, '7D', 'mean').reset_index(0, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By comparing the current transaction amount with the rolling 7-day average, I can identify transactions that deviate significantly from a cardholder's average spending behavior. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Average amounts spent per day in the past one week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df = df.resample('D', on='Transaction Date').sum().reset_index()\n",
    "daily_df['AvgAmount_perday_7days'] = daily_df['Amount'].rolling(7).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This kind of feature can assist in budgeting and monitoring cardholder expenses. It provides an average benchmark to compare individual transactions against the group ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Average amount per day spent over three days on all transactions up to this one on the same merchant type as this transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Avg_Amount_3_days_MCC'] = df.groupby('Merchant Category Code (MCC)').apply(rolling_amount, '3D', 'mean').reset_index(0, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this feature to track some bad amounts within 3 days,it helps identify spending patterns based on specific days of the week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Transaction Day of the Week: The day of the week when the transaction occurred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'Transaction Date' column contains datetime values\n",
    "df['Transaction Day of the Week'] = df['Transaction Date'].dt.dayofweek\n",
    "\n",
    "# Map day of the week numeric values to corresponding day names\n",
    "day_mapping = {0: 'Monday', 1: 'Tuesday', 2: 'Wednesday', 3: 'Thursday', 4: 'Friday', 5: 'Saturday', 6: 'Sunday'}\n",
    "df['Transaction Day of the Week'] = df['Transaction Day of the Week'].map(day_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It facilitates the identification of anomalies by detecting unexpected spending patterns on specific days of the week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.Total number of transactions on the same day up to this transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Transaction Date'] = pd.to_datetime(df['Transaction Date'])\n",
    "date_counts = df['Transaction Date'].value_counts()\n",
    "df['Total_Transactions_Same_Day'] = df['Transaction Date'].map(date_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can identifies anomalies in transaction density and unusual spikes in activity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.Total amount spent on the same day up to this transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Transaction Date'] = pd.to_datetime(df['Transaction Date'])\n",
    "df['Total_Amount_Same_Day'] = df.groupby(df['Transaction Date'].dt.date)['Amount'].cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this feature to highlights anomalies in cumulative spending amount, indicating unusual spending behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Transaction Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Year-Month'] = df['Year-Month'].astype(str)\n",
    "df['Year'] = df['Year-Month'].str[:4].astype(int)\n",
    "df['Month'] = df['Year-Month'].str[4:].astype(int)\n",
    "\n",
    "season_mapping = {1: 'Winter', 2: 'Winter', 3: 'Spring', 4: 'Spring', 5: 'Spring', 6: 'Summer',\n",
    "                  7: 'Summer', 8: 'Summer', 9: 'Fall', 10: 'Fall', 11: 'Fall', 12: 'Winter'}\n",
    "df['Season'] = df['Month'].map(season_mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can detects anomalies by comparing spending patterns with expected seasonal variations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Transaction Amount Deviation from Daily Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Transaction Date'] = pd.to_datetime(df['Transaction Date'])\n",
    "df['Daily_Avg_Amount'] = df.groupby(df['Transaction Date'].dt.date)['Amount'].transform('mean')\n",
    "df['Amount_Deviation_Daily'] = df['Amount']- df['Daily_Avg_Amount']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can tracking the average spending per day on a specific merchant type to detect the number which is too low or too high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.Transaction Amount Deviation from Merchant Category Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Merchant_Category_Avg_Amount'] = df.groupby('Merchant Category Code (MCC)')['Amount'].transform('mean')\n",
    "df['Amount_Deviation_Merchant'] = df['Amount'] -df['Merchant_Category_Avg_Amount']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helps identify big or small deviations in spending patterns compared to the average daily spending."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.Time Difference between Current and Previous Transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Transaction Date'] = pd.to_datetime(df['Transaction Date'])\n",
    "df['Previous_Transaction_Date'] = df.groupby('Cardholder Last Name')['Transaction Date'].shift()\n",
    "df['Time_Difference_Prev_Trans'] = (df['Transaction Date'] -df['Previous_Transaction_Date']).dt.total_seconds()/60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find spending variations within specific merchant categories, to classify the different one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.Frequency of Transactions within Merchant Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Merchant_Category_Frequency'] = df.groupby(['Cardholder Last Name', 'Merchant Category Code (MCC)'])['Amount'].transform('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this features can identifies patterns and anomalies in usual transaction timing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13.Transaction Amount Relative to Cardholder's Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cardholder_Avg_Amount'] = df.groupby(['Cardholder Last Name'])['Amount'].transform('mean')\n",
    "df['Amount_Relative_Cardholder'] = df['Amount'] / df['Cardholder_Avg_Amount']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indicates the wrong cardholder's engagement within specific merchant categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14.Transaction Amount Deviation from Monthly Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the type first \n",
    "df['Year-Month'] = df['Year-Month'].astype(str)\n",
    "df['Monthly_Avg_Amount'] = df.groupby('Year-Month')['Amount'].transform('mean')\n",
    "df['Amount_Deviation_Monthly'] = df['Amount'] - df['Monthly_Avg_Amount']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Captures unsual variations in spending compared to the average monthly spending."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15.Maximum Amount Spent on the Same Day up to the Current Transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Transaction Date'] = pd.to_datetime(df['Transaction Date'])\n",
    "df['Max_Amount_Same_Day'] = df.groupby(df['Transaction Date'].dt.date)['Amount'].cummax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Reflects recent transaction activity and engagement levels to detect the unnormal one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Year-Month  Agency Number                             Agency Name  \\\n",
      "31364      201310           1000               OKLAHOMA STATE UNIVERSITY   \n",
      "147048     201307          63200   SPEECH-LANGUAGE PATHOLOGY & AUDIOLOGY   \n",
      "9276       201307           1000               OKLAHOMA STATE UNIVERSITY   \n",
      "1901       201307           1000               OKLAHOMA STATE UNIVERSITY   \n",
      "3487       201307           1000               OKLAHOMA STATE UNIVERSITY   \n",
      "...           ...            ...                                     ...   \n",
      "437420     201406          77000   UNIV. OF OKLA. HEALTH SCIENCES CENTER   \n",
      "405350     201406          48000               N. E. OKLA. A & M COLLEGE   \n",
      "437481     201406          77000   UNIV. OF OKLA. HEALTH SCIENCES CENTER   \n",
      "385939     201406           1000               OKLAHOMA STATE UNIVERSITY   \n",
      "410511     201406          61000  REGIONAL UNIVERSITY SYSTEM OF OKLAHOMA   \n",
      "\n",
      "       Cardholder Last Name Cardholder First Initial  \\\n",
      "31364                Tucker                        E   \n",
      "147048                 Hall                        A   \n",
      "9276                 Ropers                        A   \n",
      "1901               Robinson                        S   \n",
      "3487                  Baugh                        R   \n",
      "...                     ...                      ...   \n",
      "437420                SMITH                        G   \n",
      "405350                48000                        4   \n",
      "437481              SANDERS                        K   \n",
      "385939             Meridith                        M   \n",
      "410511                 Lynn                        G   \n",
      "\n",
      "                                              Description    Amount  \\\n",
      "31364                                    GENERAL PURCHASE    -34.82   \n",
      "147048                                   GENERAL PURCHASE     -7.00   \n",
      "9276                                         ROOM CHARGES  15120.00   \n",
      "1901                                     GENERAL PURCHASE     -2.30   \n",
      "3487                                     GENERAL PURCHASE   -308.00   \n",
      "...                                                   ...       ...   \n",
      "437420                      CHAMBER MATRIGEL INV 24W C CS    706.88   \n",
      "405350                                   GENERAL PURCHASE    250.00   \n",
      "437481  Latitude 14 5000 Series PCE|9-cell (97Wh) 3 Ye...   4187.58   \n",
      "385939                                   GENERAL PURCHASE     17.50   \n",
      "410511  Inspiron 3542 PCE|4th Generation Intel(R) Co P...   -897.99   \n",
      "\n",
      "                           Vendor Transaction Date Posted Date  \\\n",
      "31364           UNIVERSITEIT GENT       2013-04-17  2013-10-17   \n",
      "147048    CREDIT PURCHASE BALANCE       2013-04-30  2013-07-01   \n",
      "9276         BETHESDA COURT HOTEL       2013-05-16  2013-07-24   \n",
      "1901       HYATT PLACE STOCKYARDS       2013-05-21  2013-07-02   \n",
      "3487    Claim ADJ/AMERICAS BEST V       2013-05-22  2013-07-09   \n",
      "...                           ...              ...         ...   \n",
      "437420      VWR INTERNATIONAL INC       2014-06-30  2014-06-30   \n",
      "405350           LATE PAYMENT FEE       2014-06-30  2014-06-30   \n",
      "437481      DMI  DELL HIGHER EDUC       2014-06-30  2014-06-30   \n",
      "385939     NEW YORK TIMES DIGITAL       2014-06-30  2014-06-30   \n",
      "410511       DMI  DELL BUS ONLINE       2014-06-30  2014-06-30   \n",
      "\n",
      "                             Merchant Category Code (MCC)  Avg_Amount_7_days  \\\n",
      "31364             COMBINATION CATALOG AND RETAIL MERCHANT         -34.820000   \n",
      "147048                                    DISCOUNT STORES          -7.000000   \n",
      "9276                   LODGING--HOTELS,MOTELS,AND RESORTS       15120.000000   \n",
      "1901                                   HYATT HOTELS/INT'L          -2.300000   \n",
      "3487                              AMERICAS BEST VALUE INN        -308.000000   \n",
      "...                                                   ...                ...   \n",
      "437420  DENTAL/LABORATORY/MEDICAL/OPHTHALMIC HOSP EQIP...         263.162857   \n",
      "405350                                         OTHER FEES         125.375000   \n",
      "437481  COMPUTERS, COMPUTER PERIPHERAL EQUIPMENT, SOFT...        1575.280000   \n",
      "385939                  CONTINUITY/SUBSCRIPTION MERCHANTS          87.540000   \n",
      "410511  COMPUTERS, COMPUTER PERIPHERAL EQUIPMENT, SOFT...         287.375000   \n",
      "\n",
      "        Avg_Amount_3_days_MCC Transaction Day of the Week  \\\n",
      "31364              -34.820000                   Wednesday   \n",
      "147048              -7.000000                     Tuesday   \n",
      "9276             15120.000000                    Thursday   \n",
      "1901                -2.300000                     Tuesday   \n",
      "3487              -308.000000                   Wednesday   \n",
      "...                       ...                         ...   \n",
      "437420             424.845000                      Monday   \n",
      "405350              45.663333                      Monday   \n",
      "437481            4144.756087                      Monday   \n",
      "385939              46.174545                      Monday   \n",
      "410511            3934.641667                      Monday   \n",
      "\n",
      "        Total_Transactions_Same_Day  Total_Amount_Same_Day  Year  Month  \\\n",
      "31364                             1                 -34.82  2013     10   \n",
      "147048                            1                  -7.00  2013      7   \n",
      "9276                              1               15120.00  2013      7   \n",
      "1901                              1                  -2.30  2013      7   \n",
      "3487                              1                -308.00  2013      7   \n",
      "...                             ...                    ...   ...    ...   \n",
      "437420                           20                5378.36  2014      6   \n",
      "405350                           20                5628.36  2014      6   \n",
      "437481                           20                9815.94  2014      6   \n",
      "385939                           20                9833.44  2014      6   \n",
      "410511                           20                8935.45  2014      6   \n",
      "\n",
      "        Season  Daily_Avg_Amount  Amount_Deviation_Daily  \\\n",
      "31364     Fall          -34.8200                  0.0000   \n",
      "147048  Summer           -7.0000                  0.0000   \n",
      "9276    Summer        15120.0000                  0.0000   \n",
      "1901    Summer           -2.3000                  0.0000   \n",
      "3487    Summer         -308.0000                  0.0000   \n",
      "...        ...               ...                     ...   \n",
      "437420  Summer          446.7725                260.1075   \n",
      "405350  Summer          446.7725               -196.7725   \n",
      "437481  Summer          446.7725               3740.8075   \n",
      "385939  Summer          446.7725               -429.2725   \n",
      "410511  Summer          446.7725              -1344.7625   \n",
      "\n",
      "        Merchant_Category_Avg_Amount  Amount_Deviation_Merchant  \\\n",
      "31364                     177.294199                -212.114199   \n",
      "147048                    199.764215                -206.764215   \n",
      "9276                      499.106953               14620.893047   \n",
      "1901                      482.532097                -484.832097   \n",
      "3487                      105.405833                -413.405833   \n",
      "...                              ...                        ...   \n",
      "437420                    545.258948                 161.621052   \n",
      "405350                   3306.516456               -3056.516456   \n",
      "437481                   1833.503045                2354.076955   \n",
      "385939                    153.199694                -135.699694   \n",
      "410511                   1833.503045               -2731.493045   \n",
      "\n",
      "       Previous_Transaction_Date  Time_Difference_Prev_Trans  \\\n",
      "31364                        NaT                         NaN   \n",
      "147048                       NaT                         NaN   \n",
      "9276                         NaT                         NaN   \n",
      "1901                         NaT                         NaN   \n",
      "3487                         NaT                         NaN   \n",
      "...                          ...                         ...   \n",
      "437420                2014-06-27                      4320.0   \n",
      "405350                2014-06-25                      7200.0   \n",
      "437481                2014-06-27                      4320.0   \n",
      "385939                2014-06-27                      4320.0   \n",
      "410511                2014-06-28                      2880.0   \n",
      "\n",
      "        Merchant_Category_Frequency  Cardholder_Avg_Amount  \\\n",
      "31364                             1             433.505240   \n",
      "147048                            1             146.132318   \n",
      "9276                              3            5825.789630   \n",
      "1901                              1             414.218026   \n",
      "3487                              1             155.602143   \n",
      "...                             ...                    ...   \n",
      "437420                           81             316.603926   \n",
      "405350                           13              96.774615   \n",
      "437481                           25             387.613614   \n",
      "385939                           31             382.744261   \n",
      "410511                            7             242.956597   \n",
      "\n",
      "        Amount_Relative_Cardholder  Monthly_Avg_Amount  \\\n",
      "31364                    -0.080322          435.781619   \n",
      "147048                   -0.047902          419.180430   \n",
      "9276                      2.595356          419.180430   \n",
      "1901                     -0.005553          419.180430   \n",
      "3487                     -1.979407          419.180430   \n",
      "...                            ...                 ...   \n",
      "437420                    2.232695          436.586554   \n",
      "405350                    2.583322          436.586554   \n",
      "437481                   10.803491          436.586554   \n",
      "385939                    0.045722          436.586554   \n",
      "410511                   -3.696092          436.586554   \n",
      "\n",
      "        Amount_Deviation_Monthly  Max_Amount_Same_Day  \n",
      "31364                -470.601619               -34.82  \n",
      "147048               -426.180430                -7.00  \n",
      "9276                14700.819570             15120.00  \n",
      "1901                 -421.480430                -2.30  \n",
      "3487                 -727.180430              -308.00  \n",
      "...                          ...                  ...  \n",
      "437420                270.293446              1353.22  \n",
      "405350               -186.586554              1353.22  \n",
      "437481               3750.993446              4187.58  \n",
      "385939               -419.086554              4187.58  \n",
      "410511              -1334.576554              4187.58  \n",
      "\n",
      "[442458 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)  # Set the option to display all columns\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After preprocessing the dataset and engineering relevant features, I can conclude that generate multiple features in different ways are very useful for detecting anomalies in cardholder spending behavior. For example, if a cardholder's current transaction amount deviates significantly from their average spending in the past week, it could signal potential fraudulent activity or unusual spending patterns. By monitoring and analyzing these deviations, we can identify suspicious transactions and take appropriate action to mitigate risks and protect their customers. This features can be used for unsupervised learning models and really do benefits to the accuracy of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Agency Number</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Avg_Amount_7_days</th>\n",
       "      <th>Avg_Amount_3_days_MCC</th>\n",
       "      <th>Total_Transactions_Same_Day</th>\n",
       "      <th>Total_Amount_Same_Day</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Daily_Avg_Amount</th>\n",
       "      <th>Amount_Deviation_Daily</th>\n",
       "      <th>Merchant_Category_Avg_Amount</th>\n",
       "      <th>Amount_Deviation_Merchant</th>\n",
       "      <th>Time_Difference_Prev_Trans</th>\n",
       "      <th>Merchant_Category_Frequency</th>\n",
       "      <th>Cardholder_Avg_Amount</th>\n",
       "      <th>Amount_Relative_Cardholder</th>\n",
       "      <th>Monthly_Avg_Amount</th>\n",
       "      <th>Amount_Deviation_Monthly</th>\n",
       "      <th>Max_Amount_Same_Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>442458.000000</td>\n",
       "      <td>4.424580e+05</td>\n",
       "      <td>4.424580e+05</td>\n",
       "      <td>442458.000000</td>\n",
       "      <td>442458.000000</td>\n",
       "      <td>4.424580e+05</td>\n",
       "      <td>442458.000000</td>\n",
       "      <td>442458.000000</td>\n",
       "      <td>442458.000000</td>\n",
       "      <td>4.424580e+05</td>\n",
       "      <td>442458.000000</td>\n",
       "      <td>4.424580e+05</td>\n",
       "      <td>438547.000000</td>\n",
       "      <td>442458.000000</td>\n",
       "      <td>442458.000000</td>\n",
       "      <td>4.424580e+05</td>\n",
       "      <td>442458.000000</td>\n",
       "      <td>4.424580e+05</td>\n",
       "      <td>4.424580e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>42785.860353</td>\n",
       "      <td>4.249912e+02</td>\n",
       "      <td>4.289410e+02</td>\n",
       "      <td>424.765577</td>\n",
       "      <td>1543.941807</td>\n",
       "      <td>3.354251e+05</td>\n",
       "      <td>2013.509058</td>\n",
       "      <td>6.378526</td>\n",
       "      <td>424.991170</td>\n",
       "      <td>2.423494e-15</td>\n",
       "      <td>424.991170</td>\n",
       "      <td>-9.718642e-15</td>\n",
       "      <td>3521.849380</td>\n",
       "      <td>198.506538</td>\n",
       "      <td>424.991170</td>\n",
       "      <td>NaN</td>\n",
       "      <td>424.991170</td>\n",
       "      <td>-1.234152e-14</td>\n",
       "      <td>4.545056e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>33378.461293</td>\n",
       "      <td>5.266509e+03</td>\n",
       "      <td>4.111175e+03</td>\n",
       "      <td>2491.255370</td>\n",
       "      <td>425.345374</td>\n",
       "      <td>2.709991e+05</td>\n",
       "      <td>0.499919</td>\n",
       "      <td>3.359571</td>\n",
       "      <td>535.130739</td>\n",
       "      <td>5.239251e+03</td>\n",
       "      <td>378.726005</td>\n",
       "      <td>5.252874e+03</td>\n",
       "      <td>11742.129903</td>\n",
       "      <td>607.170870</td>\n",
       "      <td>2415.589995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.290594</td>\n",
       "      <td>5.266448e+03</td>\n",
       "      <td>1.363119e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>-4.286304e+04</td>\n",
       "      <td>-2.148950e+04</td>\n",
       "      <td>-11757.590000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.199383e+04</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-3047.263333</td>\n",
       "      <td>-4.337078e+04</td>\n",
       "      <td>-243.007333</td>\n",
       "      <td>-4.305414e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-112.015000</td>\n",
       "      <td>-inf</td>\n",
       "      <td>380.471545</td>\n",
       "      <td>-4.332389e+04</td>\n",
       "      <td>-2.611940e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>3.091000e+01</td>\n",
       "      <td>1.092602e+02</td>\n",
       "      <td>136.496688</td>\n",
       "      <td>1419.000000</td>\n",
       "      <td>1.234505e+05</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>361.428038</td>\n",
       "      <td>-3.744098e+02</td>\n",
       "      <td>191.096308</td>\n",
       "      <td>-3.651786e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>196.581582</td>\n",
       "      <td>1.265425e-01</td>\n",
       "      <td>405.716869</td>\n",
       "      <td>-3.877816e+02</td>\n",
       "      <td>8.446970e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>47700.000000</td>\n",
       "      <td>1.048900e+02</td>\n",
       "      <td>2.349029e+02</td>\n",
       "      <td>290.644971</td>\n",
       "      <td>1686.000000</td>\n",
       "      <td>2.990887e+05</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>402.635719</td>\n",
       "      <td>-2.818232e+02</td>\n",
       "      <td>410.479644</td>\n",
       "      <td>-1.405419e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>289.078843</td>\n",
       "      <td>4.063248e-01</td>\n",
       "      <td>435.781619</td>\n",
       "      <td>-3.148565e+02</td>\n",
       "      <td>1.915571e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>76000.000000</td>\n",
       "      <td>3.450000e+02</td>\n",
       "      <td>4.084201e+02</td>\n",
       "      <td>490.283028</td>\n",
       "      <td>1820.000000</td>\n",
       "      <td>4.969065e+05</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>453.814693</td>\n",
       "      <td>-5.921201e+01</td>\n",
       "      <td>529.877561</td>\n",
       "      <td>-7.923427e+00</td>\n",
       "      <td>2880.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>412.368695</td>\n",
       "      <td>1.143629e+00</td>\n",
       "      <td>451.768880</td>\n",
       "      <td>-7.952813e+01</td>\n",
       "      <td>4.204754e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>98000.000000</td>\n",
       "      <td>1.903858e+06</td>\n",
       "      <td>1.903858e+06</td>\n",
       "      <td>951942.550000</td>\n",
       "      <td>2122.000000</td>\n",
       "      <td>2.648101e+06</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>343148.500000</td>\n",
       "      <td>1.902342e+06</td>\n",
       "      <td>4823.344647</td>\n",
       "      <td>1.900552e+06</td>\n",
       "      <td>528480.000000</td>\n",
       "      <td>4481.000000</td>\n",
       "      <td>609039.725000</td>\n",
       "      <td>inf</td>\n",
       "      <td>460.854807</td>\n",
       "      <td>1.903407e+06</td>\n",
       "      <td>1.903858e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Agency Number        Amount  Avg_Amount_7_days  Avg_Amount_3_days_MCC  \\\n",
       "count  442458.000000  4.424580e+05       4.424580e+05          442458.000000   \n",
       "mean    42785.860353  4.249912e+02       4.289410e+02             424.765577   \n",
       "std     33378.461293  5.266509e+03       4.111175e+03            2491.255370   \n",
       "min      1000.000000 -4.286304e+04      -2.148950e+04          -11757.590000   \n",
       "25%      1000.000000  3.091000e+01       1.092602e+02             136.496688   \n",
       "50%     47700.000000  1.048900e+02       2.349029e+02             290.644971   \n",
       "75%     76000.000000  3.450000e+02       4.084201e+02             490.283028   \n",
       "max     98000.000000  1.903858e+06       1.903858e+06          951942.550000   \n",
       "\n",
       "       Total_Transactions_Same_Day  Total_Amount_Same_Day           Year  \\\n",
       "count                442458.000000           4.424580e+05  442458.000000   \n",
       "mean                   1543.941807           3.354251e+05    2013.509058   \n",
       "std                     425.345374           2.709991e+05       0.499919   \n",
       "min                       1.000000          -2.199383e+04    2013.000000   \n",
       "25%                    1419.000000           1.234505e+05    2013.000000   \n",
       "50%                    1686.000000           2.990887e+05    2014.000000   \n",
       "75%                    1820.000000           4.969065e+05    2014.000000   \n",
       "max                    2122.000000           2.648101e+06    2014.000000   \n",
       "\n",
       "               Month  Daily_Avg_Amount  Amount_Deviation_Daily  \\\n",
       "count  442458.000000     442458.000000            4.424580e+05   \n",
       "mean        6.378526        424.991170            2.423494e-15   \n",
       "std         3.359571        535.130739            5.239251e+03   \n",
       "min         1.000000      -3047.263333           -4.337078e+04   \n",
       "25%         3.000000        361.428038           -3.744098e+02   \n",
       "50%         6.000000        402.635719           -2.818232e+02   \n",
       "75%         9.000000        453.814693           -5.921201e+01   \n",
       "max        12.000000     343148.500000            1.902342e+06   \n",
       "\n",
       "       Merchant_Category_Avg_Amount  Amount_Deviation_Merchant  \\\n",
       "count                 442458.000000               4.424580e+05   \n",
       "mean                     424.991170              -9.718642e-15   \n",
       "std                      378.726005               5.252874e+03   \n",
       "min                     -243.007333              -4.305414e+04   \n",
       "25%                      191.096308              -3.651786e+02   \n",
       "50%                      410.479644              -1.405419e+02   \n",
       "75%                      529.877561              -7.923427e+00   \n",
       "max                     4823.344647               1.900552e+06   \n",
       "\n",
       "       Time_Difference_Prev_Trans  Merchant_Category_Frequency  \\\n",
       "count               438547.000000                442458.000000   \n",
       "mean                  3521.849380                   198.506538   \n",
       "std                  11742.129903                   607.170870   \n",
       "min                      0.000000                     1.000000   \n",
       "25%                      0.000000                     7.000000   \n",
       "50%                      0.000000                    24.000000   \n",
       "75%                   2880.000000                    84.000000   \n",
       "max                 528480.000000                  4481.000000   \n",
       "\n",
       "       Cardholder_Avg_Amount  Amount_Relative_Cardholder  Monthly_Avg_Amount  \\\n",
       "count          442458.000000                4.424580e+05       442458.000000   \n",
       "mean              424.991170                         NaN          424.991170   \n",
       "std              2415.589995                         NaN           25.290594   \n",
       "min              -112.015000                        -inf          380.471545   \n",
       "25%               196.581582                1.265425e-01          405.716869   \n",
       "50%               289.078843                4.063248e-01          435.781619   \n",
       "75%               412.368695                1.143629e+00          451.768880   \n",
       "max            609039.725000                         inf          460.854807   \n",
       "\n",
       "       Amount_Deviation_Monthly  Max_Amount_Same_Day  \n",
       "count              4.424580e+05         4.424580e+05  \n",
       "mean              -1.234152e-14         4.545056e+04  \n",
       "std                5.266448e+03         1.363119e+05  \n",
       "min               -4.332389e+04        -2.611940e+03  \n",
       "25%               -3.877816e+02         8.446970e+03  \n",
       "50%               -3.148565e+02         1.915571e+04  \n",
       "75%               -7.952813e+01         4.204754e+04  \n",
       "max                1.903407e+06         1.903858e+06  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 442458 entries, 31364 to 410511\n",
      "Data columns (total 31 columns):\n",
      " #   Column                        Non-Null Count   Dtype         \n",
      "---  ------                        --------------   -----         \n",
      " 0   Year-Month                    442458 non-null  object        \n",
      " 1   Agency Number                 442458 non-null  int64         \n",
      " 2   Agency Name                   442458 non-null  object        \n",
      " 3   Cardholder Last Name          442458 non-null  object        \n",
      " 4   Cardholder First Initial      442458 non-null  object        \n",
      " 5   Description                   442458 non-null  object        \n",
      " 6   Amount                        442458 non-null  float64       \n",
      " 7   Vendor                        442458 non-null  object        \n",
      " 8   Transaction Date              442458 non-null  datetime64[ns]\n",
      " 9   Posted Date                   442458 non-null  datetime64[ns]\n",
      " 10  Merchant Category Code (MCC)  442458 non-null  object        \n",
      " 11  Avg_Amount_7_days             442458 non-null  float64       \n",
      " 12  Avg_Amount_3_days_MCC         442458 non-null  float64       \n",
      " 13  Transaction Day of the Week   442458 non-null  object        \n",
      " 14  Total_Transactions_Same_Day   442458 non-null  int64         \n",
      " 15  Total_Amount_Same_Day         442458 non-null  float64       \n",
      " 16  Year                          442458 non-null  int32         \n",
      " 17  Month                         442458 non-null  int32         \n",
      " 18  Season                        442458 non-null  object        \n",
      " 19  Daily_Avg_Amount              442458 non-null  float64       \n",
      " 20  Amount_Deviation_Daily        442458 non-null  float64       \n",
      " 21  Merchant_Category_Avg_Amount  442458 non-null  float64       \n",
      " 22  Amount_Deviation_Merchant     442458 non-null  float64       \n",
      " 23  Previous_Transaction_Date     438547 non-null  datetime64[ns]\n",
      " 24  Time_Difference_Prev_Trans    438547 non-null  float64       \n",
      " 25  Merchant_Category_Frequency   442458 non-null  int64         \n",
      " 26  Cardholder_Avg_Amount         442458 non-null  float64       \n",
      " 27  Amount_Relative_Cardholder    442458 non-null  float64       \n",
      " 28  Monthly_Avg_Amount            442458 non-null  float64       \n",
      " 29  Amount_Deviation_Monthly      442458 non-null  float64       \n",
      " 30  Max_Amount_Same_Day           442458 non-null  float64       \n",
      "dtypes: datetime64[ns](3), float64(14), int32(2), int64(3), object(9)\n",
      "memory usage: 104.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3 Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Binning 'Amount' column\n",
    "num_bins = 5  # Specify the number of bins\n",
    "df['Amount_Binned'] = pd.cut(df['Amount'], bins=num_bins, labels=False)\n",
    "\n",
    "# Binning 'Avg_Amount_7_days' column\n",
    "custom_bins = [0, 100, 500, 1000, float('inf')]  # Define custom bin edges\n",
    "df['Avg_Amount_7_days_Binned'] = pd.cut(df['Avg_Amount_7_days'], bins=custom_bins, labels=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Generate New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute statistical features\n",
    "df['Amount_Mean'] = df.groupby(['Vendor'])['Amount'].transform('mean')\n",
    "df['Amount_Std'] = df.groupby(['Vendor'])['Amount'].transform('std')\n",
    "df['Total_Amount_Same_Day_Min'] = df.groupby(['Vendor'])['Total_Amount_Same_Day'].transform('min')\n",
    "df['Total_Amount_Same_Day_Max'] = df.groupby(['Vendor'])['Total_Amount_Same_Day'].transform('max')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contamination = 0.05\n",
    "# n_train = 500\n",
    "# n_test = 500\n",
    "# n_features = 6\n",
    "\n",
    "# X_train, X_test, y_train, y_test = generate_data(\n",
    "#     n_train=n_train,\n",
    "#     n_test=n_test,\n",
    "#     n_features=n_features,\n",
    "#     contamination=contamination,\n",
    "#     random_state=123\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first section of the code is used for data generation. The generate_data function from PyOD's utility is used to generate random data for training and testing. The number of samples in training and test data is 500 each, with 6 features. The contamination rate is set to 0.05, meaning that approximately 5% of the total data points are outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Model Training and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\STEVEN H\\Anaconda3\\envs\\week-1\\lib\\site-packages\\sklearn\\feature_extraction\\image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int):\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-dc813eea64b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhbos\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHBOS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mhbos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHBOS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontamination\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcontamination\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mhbos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_train_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhbos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from pyod.models.hbos import HBOS\n",
    "hbos = HBOS(contamination=contamination)\n",
    "hbos.fit(X_train)\n",
    "\n",
    "y_train_scores = hbos.decision_function(X_train)\n",
    "y_train_pred = hbos.predict(X_train)\n",
    "\n",
    "y_test_scores = hbos.decision_function(X_test)\n",
    "y_test_pred = hbos.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we instantiate and fit the HBOS (Histogram-Based Outlier Score) model, a fast unsupervised anomaly detector. The contamination parameter is used to define the proportion of outliers in the data. The predict function is used to predict if a particular sample is an outlier or not. The decision_function calculates the anomaly score for each observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Statistics and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = hbos.threshold_\n",
    "print(\"The threshold for the defined contamination rate:\", threshold)\n",
    "print(\"Training data:\", count_stat(y_train_pred))\n",
    "print(\"Test data:\", count_stat(y_test_pred))\n",
    "plt.hist(y_test_scores, bins='auto')\n",
    "plt.title(\"Histogram of Anomaly Scores\")\n",
    "plt.xlabel(\"HBOS\")\n",
    "plt.show()\n",
    "descriptive_stat = descriptive_stat_threshold(X_train, y_train_scores, threshold)\n",
    "print(descriptive_stat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The very low values between 11 and 17 suggest that there are very few data points that the model considers to be mildly anomalous. The low values between 7 and 11 indicate that even fewer data points are considered strongly anomalous.\n",
    "\n",
    "This information can be used to set a threshold for determining which points to consider as outliers. We can might decide to label all points with a score from 7-11 as outliers, as they represent the top end of the anomaly score distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_train = confusion_matrix(y_train, y_train_scores, threshold)\n",
    "print(\"Confusion matrix for training data:\")\n",
    "print(cm_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e. Hyperparameters Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Define the range of contamination values\n",
    "contamination_values = np.linspace(0.01, 0.1, 10)\n",
    "\n",
    "# Initialize lists to store the results\n",
    "f1_scores_train = []\n",
    "f1_scores_test = []\n",
    "\n",
    "# Loop over the contamination values\n",
    "for contamination in contamination_values:\n",
    "    # Fit the HBOS model\n",
    "    hbos = HBOS(contamination=contamination)\n",
    "    hbos.fit(X_train)\n",
    "    \n",
    "    # Predict the labels for the training data and compute the F1-score\n",
    "    y_train_pred = hbos.predict(X_train)\n",
    "    f1_train = f1_score(y_train, y_train_pred)\n",
    "    f1_scores_train.append(f1_train)\n",
    "    \n",
    "    # Predict the labels for the test data and compute the F1-score\n",
    "    y_test_pred = hbos.predict(X_test)\n",
    "    f1_test = f1_score(y_test, y_test_pred)\n",
    "    f1_scores_test.append(f1_test)\n",
    "\n",
    "# Plot the F1-scores as a function of the contamination parameter\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(contamination_values, f1_scores_train, label='Train')\n",
    "plt.plot(contamination_values, f1_scores_test, label='Test')\n",
    "plt.xlabel('Contamination')\n",
    "plt.ylabel('F1-score')\n",
    "plt.legend()\n",
    "plt.title('Hyperparameter Tuning of HBOS Contamination Parameter')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When contamination is between 0 and 0.05, both the training and test scores are improving. This suggests that the model is learning the underlying patterns in the data and generalizing well to unseen data.\n",
    "\n",
    "Thus, in this case, the optimal contamination parameter appears to be around 0.05, where the test F1-score is at its peak. It's essential to remember that the exact value may vary depending on the randomness in the data split and other factors. Therefore, it's good practice to perform multiple runs or use cross-validation to confirm the optimal parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ECODS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Generation and Histogram Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram plotted provides a visual representation of the frequency of data points in different ranges. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a distribution\n",
    "np.random.seed(123)\n",
    "shape, scale = 10, 2\n",
    "s1 = np.random.gamma(shape, scale, 1000)\n",
    "s2 = np.random.gamma(shape * 2, scale * 2, 1000)\n",
    "s3 = np.random.normal(loc=0, scale=5, size=1000)\n",
    "sample = np.hstack((s1, s2, s3))\n",
    "\n",
    "# Plot the histogram\n",
    "plt.hist(sample, bins=50)\n",
    "plt.title('Histogram')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Empirical Cumulative Distribution Function (CDF) Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a CDF\n",
    "sample_ecdf = ECDF(sample)\n",
    "\n",
    "# Plot the CDF\n",
    "plt.plot(sample_ecdf.x, sample_ecdf.y)\n",
    "plt.title('Empirical CDF')\n",
    "plt.show()\n",
    "\n",
    "# Calculate probabilities using the ECDF\n",
    "probabilities = [-20, -2, 0, 25, 50, 75, 100, 125, 140, 150]\n",
    "for p in probabilities:\n",
    "    print('P(x < {}): {:.4f}'.format(p, sample_ecdf(p)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the histogram, I fit an Empirical Cumulative Distribution Function (ECDF) to the sample data. The ECDF plot reveals how the probabilities are distributed across the entire sample. With the printed probabilities, it's evident that the majority of the data points fall between 25 and 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Synthetic Dataset Generation and Scatter Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic dataset\n",
    "contamination = 0.05  # percentage of outliers\n",
    "n_train = 350000      # number of training points\n",
    "n_test = 92458        # number of testing points\n",
    "X_train, X_test, _, _ = generate_data(\n",
    "    n_train=n_train,\n",
    "    n_test=n_test,\n",
    "    n_features=df.shape[1],\n",
    "    contamination=contamination,\n",
    "    random_state=123\n",
    ")\n",
    "X_train_pd = pd.DataFrame(X_train)\n",
    "\n",
    "# Plot the scatter plot of the first two features\n",
    "plt.scatter(X_train_pd.iloc[:, 0], X_train_pd.iloc[:, 1], alpha=0.8)\n",
    "plt.title('Scatter Plot')\n",
    "plt.xlabel('Feature 0')\n",
    "plt.ylabel('Feature 1')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scatter plot of the first two features provides a visual understanding of the data spread and potentially identify regions where outliers may exist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model Fitting and Predicting with ECOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit ECOD model\n",
    "ecod = ECOD(contamination=contamination)\n",
    "ecod.fit(X_train)\n",
    "\n",
    "# Training data\n",
    "y_train_scores = ecod.decision_function(X_train)\n",
    "y_train_pred = ecod.predict(X_train)\n",
    "\n",
    "# Test data\n",
    "X_test_pd = pd.DataFrame(X_test)\n",
    "y_test_scores = ecod.decision_function(X_test)\n",
    "y_test_pred = ecod.predict(X_test)\n",
    "\n",
    "# Count statistics\n",
    "print(\"Training Data:\", count_stat(y_train_pred))\n",
    "print(\"Testing Data:\", count_stat(y_test_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find outliers within this synthetic dataset, I employed the Ensemble of Covariance-based Outlier Detectors (ECOD) model. After fitting the model, it was used to predict both on the training and testing data, providing an initial assessment of how well the model can identify outliers. With the training data, the ECOD model identified 17,500 data points as outliers (5% of the data), which matches the contamination factor I had initially set, suggesting a good fit for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Outlier Score Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of outlier scores\n",
    "plt.hist(y_train_scores, bins='auto')\n",
    "plt.title('Outlier Score Distribution')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram of these scores displays the distribution of outlier scores. The varying range of scores suggests that the outliers are spread across different regions of the data space. The outliers mainly assembled between 40 80, a small number between 120-160."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Descriptive Statistics Based on Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics based on the threshold\n",
    "def descriptive_stat_threshold(df, pred_score, threshold):\n",
    "    df = pd.DataFrame(df)\n",
    "    df['Anomaly_Score'] = pred_score\n",
    "    df['Group'] = np.where(df['Anomaly_Score'] < threshold, 'Normal', 'Outlier')\n",
    "    cnt = df.groupby('Group')['Anomaly_Score'].count().reset_index().rename(columns={'Anomaly_Score': 'Count'})\n",
    "    cnt['Count %'] = (cnt['Count'] / cnt['Count'].sum()) * 100\n",
    "    stat = df.groupby('Group').mean().round(2).reset_index()\n",
    "    stat = cnt.merge(stat, left_on='Group', right_on='Group')\n",
    "    return stat\n",
    "\n",
    "threshold = ecod.threshold_\n",
    "descriptive_stats = descriptive_stat_threshold(X_train, y_train_scores, threshold)\n",
    "print(descriptive_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " It is noticeable from the output that normal data points have higher average values across all features compared to outliers. The anomaly score for the outlier group is considerably higher than that of the normal group, confirming the effectiveness of the ECOD model in distinguishing between normal and anomalous observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic dataset with ground truth labels\n",
    "X_train, X_test, y_train, y_test = generate_data(\n",
    "    n_train=n_train,\n",
    "    n_test=n_test,\n",
    "    n_features=df.shape[1],\n",
    "    contamination=contamination,\n",
    "    random_state=123\n",
    ")\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Make sure the labels are in the same format\n",
    "y_train = y_train.astype(int)\n",
    "\n",
    "# Build confusion matrix\n",
    "cm = confusion_matrix(y_train, y_train_pred)\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, to evaluate the model's performance, I generated a confusion matrix for the model's predictions on the training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, the ECOD model was successful in identifying outliers in the synthetic dataset, which could represent significant anomalous events depending on the specific business context. By identifying these outliers, necessary preventative measures can be taken to address the issues they may represent. These could range from fraudulent transactions in finance to sensor malfunctions in machinery. The provided analysis and summary statistics offer a comprehensive understanding of the underlying data and the behavior of the outliers, allowing for insightful and data-driven decision-making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
